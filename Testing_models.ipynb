{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "682d5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, RobustScaler, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2abd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DATA LOADING\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "hospital_id_test = test[\"Hospital_Id\"]\n",
    "drop_cols = [\"Hospital_Id\", \"Supplier_Name\", \"Hospital_Location\"]\n",
    "train = train.drop(columns=drop_cols)\n",
    "test = test.drop(columns=drop_cols)\n",
    "\n",
    "target = \"Transport_Cost\"\n",
    "train = train.dropna(subset=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b7f61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed outliers above 80th percentile (>-538.65). Remaining samples: 4780\n"
     ]
    }
   ],
   "source": [
    "#  REMOVE OUTLIERS ABOVE 80th PERCENTILE\n",
    "\n",
    "q80 = train[target].quantile(0.044)\n",
    "train = train[train[target] >= q80]\n",
    "print(f\"Removed outliers above 80th percentile (>{q80:.2f}). Remaining samples: {len(train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2edbd65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FEATURE GROUPS\n",
    "\n",
    "numeric_features_median = ['Equipment_Height', 'Equipment_Weight', 'Supplier_Reliability']\n",
    "categorical_features_unknown = ['Equipment_Type', 'Transport_Method', 'Rural_Hospital']\n",
    "no_missing_features_numerical = ['Equipment_Value', 'Base_Transport_Fee']\n",
    "no_missing_features_categorical = ['Fragile_Equipment', 'Hospital_Info', 'CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service']\n",
    "date_features = ['Order_Placed_Date', 'Delivery_Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62375cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DATE FUNCTION\n",
    "\n",
    "def compute_date_features(df_dates):\n",
    "    df = df_dates.copy()\n",
    "    df = df.apply(pd.to_datetime, format=\"%m/%d/%y\", errors=\"coerce\")\n",
    "    order = df.iloc[:, 0]\n",
    "    delivery = df.iloc[:, 1]\n",
    "    delivery_days = (delivery - order).dt.days\n",
    "    order_dow = order.dt.dayofweek.fillna(-1).astype(float)\n",
    "    order_month = order.dt.month.fillna(0).astype(float)\n",
    "    delivery_dow = delivery.dt.dayofweek.fillna(-1).astype(float)\n",
    "    delivery_month = delivery.dt.month.fillna(0).astype(float)\n",
    "    order_is_weekend = order_dow.isin([5, 6]).astype(float)\n",
    "    delivery_is_weekend = delivery_dow.isin([5, 6]).astype(float)\n",
    "\n",
    "    def cyc(x, period):\n",
    "        xr = x.replace(-1, 0)\n",
    "        rad = 2 * np.pi * xr / period\n",
    "        return np.sin(rad), np.cos(rad)\n",
    "\n",
    "    order_dow_sin, order_dow_cos = cyc(order_dow, 7)\n",
    "    order_month_sin, order_month_cos = cyc(order_month, 12)\n",
    "\n",
    "    features = pd.DataFrame({\n",
    "        \"delivery_days\": delivery_days,\n",
    "        \"order_dow_sin\": order_dow_sin,\n",
    "        \"order_dow_cos\": order_dow_cos,\n",
    "        \"order_month_sin\": order_month_sin,\n",
    "        \"order_month_cos\": order_month_cos,\n",
    "    })\n",
    "    features.index = df_dates.index\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "821ee06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent', add_indicator=True)),\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "no_missing_numerical_transformer = Pipeline([\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "no_missing_categorical_transformer = Pipeline([\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "date_transformer = Pipeline([\n",
    "    ('date_feat', FunctionTransformer(compute_date_features, validate=False)),\n",
    "    ('imputer', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "    ('scaler', RobustScaler(with_centering=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features_median),\n",
    "    ('cat_unknown', categorical_transformer, categorical_features_unknown),\n",
    "    ('date', date_transformer, date_features),\n",
    "    ('num_no_missing', no_missing_numerical_transformer, no_missing_features_numerical),\n",
    "    ('cat_no_missing', no_missing_categorical_transformer, no_missing_features_categorical)\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce49ff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set saved as 'train_processed.csv' with 3824 rows\n",
      "Validation set saved as 'val_processed.csv' with 956 rows\n"
     ]
    }
   ],
   "source": [
    "# TRAIN-VALIDATION SPLIT\n",
    "\n",
    "X = train.drop(columns=[target])\n",
    "y = train[target].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Combine features and target for train set\n",
    "train_processed = X_train.copy()\n",
    "train_processed[target] = y_train\n",
    "\n",
    "# Combine features and target for validation set\n",
    "val_processed = X_val.copy()\n",
    "val_processed[target] = y_val\n",
    "\n",
    "# Save to CSV files\n",
    "train_processed.to_csv('train_processed.csv', index=False)\n",
    "val_processed.to_csv('val_processed.csv', index=False)\n",
    "\n",
    "print(f\"Train set saved as 'train_processed.csv' with {len(train_processed)} rows\")\n",
    "print(f\"Validation set saved as 'val_processed.csv' with {len(val_processed)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74953f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MODEL DEFINITIONS\n",
    "\n",
    "#  !!!! PLEASE READ THIS !!!! \n",
    "\n",
    "#  UNCOMMENT WHICHEVER MODEL YOU WANT TO TRY OUT BOTH IN THE MODELS AND THE PARAMETERS GRID BLOCK\n",
    "#  YOU CAN USE MULTIPLE MODELS AT ONCE BY UNCOMMENTING THEM...\n",
    "#  THIS WAS YOU CAN GET A PERFORMANCE COMPARISON USING THE VALIDATION DATA SET...\n",
    "\n",
    "models = {\n",
    "    # 'Linear Regression': Pipeline([\n",
    "    #     ('preprocessor', preprocessor),\n",
    "    #     ('regressor', TransformedTargetRegressor(\n",
    "    #         regressor=LinearRegression(),\n",
    "    #         transformer=PowerTransformer(method='yeo-johnson')\n",
    "    #     ))\n",
    "    # ]),\n",
    "    \n",
    "    # 'Lasso Regression': Pipeline([\n",
    "    #     ('preprocessor', preprocessor),\n",
    "    #     ('regressor', TransformedTargetRegressor(\n",
    "    #         regressor=Lasso(max_iter=10000, random_state=42),\n",
    "    #         transformer=PowerTransformer(method='yeo-johnson')\n",
    "    #     ))\n",
    "    # ]),\n",
    "    \n",
    "    # 'Elastic Net': Pipeline([\n",
    "    #     ('preprocessor', preprocessor),\n",
    "    #     ('regressor', TransformedTargetRegressor(\n",
    "    #         regressor=ElasticNet(max_iter=10000, random_state=42),\n",
    "    #         transformer=PowerTransformer(method='yeo-johnson')\n",
    "    #     ))\n",
    "    # ]),\n",
    "    \n",
    "    # 'K-Nearest Neighbors': Pipeline([\n",
    "    #     ('preprocessor', preprocessor),\n",
    "    #     ('regressor', KNeighborsRegressor())\n",
    "    # ]),\n",
    "    \n",
    "    'Bayesian Ridge': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', TransformedTargetRegressor(\n",
    "            regressor=BayesianRidge(),\n",
    "            transformer=PowerTransformer(method='yeo-johnson')\n",
    "        ))\n",
    "    ]),\n",
    "    \n",
    "    # 'Decision Tree': Pipeline([\n",
    "    #     ('preprocessor', preprocessor),\n",
    "    #     ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "    # ]),\n",
    "    \n",
    "    # 'Random Forest': Pipeline([\n",
    "    #     ('preprocessor', preprocessor),\n",
    "    #     ('regressor', RandomForestRegressor(random_state=42, n_jobs=1))\n",
    "    # ]),\n",
    "    \n",
    "    # 'Gradient Boosting': Pipeline([\n",
    "    #     ('preprocessor', preprocessor),\n",
    "    #     ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "    # ]),\n",
    "    \n",
    "    # 'AdaBoost': Pipeline([\n",
    "    #     ('preprocessor', preprocessor),\n",
    "    #     ('regressor', AdaBoostRegressor(random_state=42))\n",
    "    # ])\n",
    "}\n",
    "\n",
    "\n",
    "#  HYPERPARAMETER GRIDS\n",
    "\n",
    "param_grids = {\n",
    "    # 'Linear Regression': {},\n",
    "    \n",
    "    # 'Lasso Regression': {\n",
    "    #     'regressor__regressor__alpha': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "    # },\n",
    "    \n",
    "    # 'Elastic Net': {\n",
    "    #     'regressor__regressor__alpha': [0.001, 0.01, 0.1, 1.0],\n",
    "    #     'regressor__regressor__l1_ratio': [0.2, 0.5, 0.8]\n",
    "    # },\n",
    "    \n",
    "    # 'K-Nearest Neighbors': {\n",
    "    #     'regressor__n_neighbors': [3, 5, 7, 9],\n",
    "    #     'regressor__weights': ['uniform', 'distance']\n",
    "    # },\n",
    "    \n",
    "    'Bayesian Ridge': {\n",
    "        'regressor__regressor__alpha_1': [1e-6, 1e-5, 1e-4],\n",
    "        'regressor__regressor__alpha_2': [1e-6, 1e-5, 1e-4]\n",
    "    },\n",
    "    \n",
    "    # 'Decision Tree': {\n",
    "    #     'regressor__max_depth': [3, 5, 7, 10, None],\n",
    "    #     'regressor__min_samples_split': [2, 5, 10]\n",
    "    # },\n",
    "    \n",
    "    # 'Random Forest': {\n",
    "    #     'regressor__n_estimators': [50, 100, 200],\n",
    "    #     'regressor__max_depth': [5, 10, None],\n",
    "    #     'regressor__min_samples_split': [2, 5]\n",
    "    # },\n",
    "    \n",
    "    # 'Gradient Boosting': {\n",
    "    #     'regressor__n_estimators': [50, 100, 200],\n",
    "    #     'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "    #     'regressor__max_depth': [3, 4, 5]\n",
    "    # },\n",
    "    \n",
    "    # 'AdaBoost': {\n",
    "    #     'regressor__n_estimators': [50, 100, 200],\n",
    "    #     'regressor__learning_rate': [0.01, 0.1, 1.0]\n",
    "    # }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c5cb9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL TRAINING AND PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      " Training Bayesian Ridge...\n",
      "   Best params: {'regressor__regressor__alpha_1': 0.0001, 'regressor__regressor__alpha_2': 1e-06}\n",
      "   Bayesian Ridge completed\n",
      "   Training R²: 0.0388 | Validation R²: 0.0144\n",
      "   Training RMSE: 255769.83 | Validation RMSE: 297816.53\n",
      "\n",
      "======================================================================\n",
      "MODEL PERFORMANCE SUMMARY\n",
      "======================================================================\n",
      "\n",
      " PERFORMANCE RANKING (by Validation R²):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model                     Train R²   Val R²     Train RMSE   Val RMSE     Train MAE    Val MAE     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Bayesian Ridge            0.0388     0.0144     255769.83    297816.53    16723.77     14913.14    \n",
      "\n",
      " MODEL: Bayesian Ridge\n",
      "   Validation R²: 0.0144\n",
      "   Validation RMSE: 297816.53\n"
     ]
    }
   ],
   "source": [
    "#  MODEL TRAINING AND EVALUATION\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL TRAINING AND PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = {}\n",
    "best_models = {}\n",
    "\n",
    "for model_name in models.keys():\n",
    "    print(f\"\\n Training {model_name}...\")\n",
    "    \n",
    "    if param_grids[model_name]:\n",
    "        # Use GridSearchCV for models with hyperparameters\n",
    "        grid_search = GridSearchCV(\n",
    "            models[model_name],\n",
    "            param_grids[model_name],\n",
    "            cv=5,\n",
    "            scoring='r2',\n",
    "            n_jobs=1,\n",
    "            verbose=0\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        print(f\"   Best params: {best_params}\")\n",
    "    else:\n",
    "        # Train directly for models without hyperparameters\n",
    "        best_model = models[model_name]\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = \"No hyperparameter tuning\"\n",
    "    \n",
    "    # Store best model\n",
    "    best_models[model_name] = best_model\n",
    "    \n",
    "    # Validation predictions\n",
    "    y_pred_val = best_model.predict(X_val)\n",
    "    \n",
    "    # Train final model on full training data\n",
    "    final_model = best_model\n",
    "    final_model.fit(X, y)\n",
    "    y_pred_train = final_model.predict(X)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y, y_pred_train)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y, y_pred_train))\n",
    "    train_mae = mean_absolute_error(y, y_pred_train)\n",
    "    \n",
    "    val_r2 = r2_score(y_val, y_pred_val)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    \n",
    "    # Calculate MAPE (handle division by zero)\n",
    "    try:\n",
    "        train_mape = np.mean(np.abs((y - y_pred_train) / y)) * 100\n",
    "        val_mape = np.mean(np.abs((y_val - y_pred_val) / y_val)) * 100\n",
    "    except:\n",
    "        train_mape = np.nan\n",
    "        val_mape = np.nan\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'train_r2': train_r2,\n",
    "        'train_rmse': train_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'train_mape': train_mape,\n",
    "        'val_r2': val_r2,\n",
    "        'val_rmse': val_rmse,\n",
    "        'val_mae': val_mae,\n",
    "        'val_mape': val_mape,\n",
    "        'best_params': best_params\n",
    "    }\n",
    "    \n",
    "    print(f\"   {model_name} completed\")\n",
    "    print(f\"   Training R²: {train_r2:.4f} | Validation R²: {val_r2:.4f}\")\n",
    "    print(f\"   Training RMSE: {train_rmse:.2f} | Validation RMSE: {val_rmse:.2f}\")\n",
    "\n",
    "\n",
    "#  PERFORMANCE ANALYSIS\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('val_r2', ascending=False)\n",
    "\n",
    "print(\"\\n PERFORMANCE RANKING (by Validation R²):\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'Model':<25} {'Train R²':<10} {'Val R²':<10} {'Train RMSE':<12} {'Val RMSE':<12} {'Train MAE':<12} {'Val MAE':<12}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for model_name in results_df.index:\n",
    "    r = results[model_name]\n",
    "    print(f\"{model_name:<25} {r['train_r2']:<10.4f} {r['val_r2']:<10.4f} {r['train_rmse']:<12.2f} {r['val_rmse']:<12.2f} {r['train_mae']:<12.2f} {r['val_mae']:<12.2f}\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = results_df.index[0]\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f\"\\n MODEL: {best_model_name}\")\n",
    "print(f\"   Validation R²: {results[best_model_name]['val_r2']:.4f}\")\n",
    "print(f\"   Validation RMSE: {results[best_model_name]['val_rmse']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96cf378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA SUMMARY AND FINAL PREDICTIONS\n",
      "======================================================================\n",
      "\n",
      " DATA SUMMARY:\n",
      "   Training samples: 4780\n",
      "   Validation samples: 956\n",
      "   Target variable range: -538.58 - 11143428.25\n",
      "   Target variable mean: 19341.05\n",
      "   Target variable std: 260912.38\n",
      "\n",
      " Making final predictions with best model: Bayesian Ridge\n",
      " submission created successfully\n",
      "   Test predictions range: -80.40 - 765318.70\n",
      "   Test predictions mean: 5653.68\n",
      "   Test predictions std: 41137.19\n"
     ]
    }
   ],
   "source": [
    "#  DATA SUMMARY AND FINAL PREDICTIONS\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA SUMMARY AND FINAL PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n DATA SUMMARY:\")\n",
    "print(f\"   Training samples: {len(X)}\")\n",
    "print(f\"   Validation samples: {len(X_val)}\")\n",
    "print(f\"   Target variable range: {y.min():.2f} - {y.max():.2f}\")\n",
    "print(f\"   Target variable mean: {y.mean():.2f}\")\n",
    "print(f\"   Target variable std: {y.std():.2f}\")\n",
    "\n",
    "# Make predictions with best model\n",
    "print(f\"\\n Making final predictions with best model: {best_model_name}\")\n",
    "y_pred_test = best_model.predict(test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Hospital_Id\": hospital_id_test,\n",
    "    \"Transport_Cost\": y_pred_test\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(f\" submission created successfully\")\n",
    "print(f\"   Test predictions range: {y_pred_test.min():.2f} - {y_pred_test.max():.2f}\")\n",
    "print(f\"   Test predictions mean: {y_pred_test.mean():.2f}\")\n",
    "print(f\"   Test predictions std: {y_pred_test.std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
